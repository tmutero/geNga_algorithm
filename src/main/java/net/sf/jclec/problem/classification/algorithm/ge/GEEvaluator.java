package net.sf.jclec.problem.classification.algorithm.bojarczuk;

import java.util.Comparator;

import net.sf.jclec.IFitness;
import net.sf.jclec.IIndividual;
import net.sf.jclec.base.AbstractParallelEvaluator;
import net.sf.jclec.fitness.SimpleValueFitness;
import net.sf.jclec.fitness.ValueFitnessComparator;
import net.sf.jclec.problem.classification.base.Rule;
import net.sf.jclec.problem.classification.syntaxtree.SyntaxTreeRuleIndividual;
import net.sf.jclec.problem.util.dataset.IDataset;
import net.sf.jclec.problem.util.dataset.instance.IInstance;
import net.sf.jclec.problem.util.dataset.attribute.CategoricalAttribute;
import net.sf.jclec.problem.util.dataset.metadata.IMetadata;

/**
 * Evaluator for Bojarczuk et al. 2004 - A constrained-syntax genetic programming system for discovering classification rules: application to medical data sets<p/>
 * 
 * The fitness function evaluates the confusion matrix for each of the data classes.
 * The predicted class whose sensitivity and specificity is maximal is selected as the consequent of the rule.
 * Finally, the fitness is weighted as regards of the length of the rule (number of nodes). 
 * Therefore, the evolutionary process is biased to evolve accurate, simple and more comprehensible rules.
 * 
 */

public class BojarczukEvaluator extends AbstractParallelEvaluator
{
	/////////////////////////////////////////////////////////////////
	// --------------------------------------- Serialization constant
	/////////////////////////////////////////////////////////////////

	/** Generated by Eclipse */
	
	private static final long serialVersionUID = 3613350191235561000L;

	/////////////////////////////////////////////////////////////////
	// --------------------------------------------------- Properties
	/////////////////////////////////////////////////////////////////
	
	/** Train Dataset */
	
	protected IDataset dataset;
	
	/** Maximize the fitness function */
	
	private boolean maximize = true;

	/** Maximum derivation size */
	
	protected int maxDerivSize;

	/** Fitness comparator */
	
	protected transient ValueFitnessComparator comparator = new ValueFitnessComparator(!maximize);
	
	/////////////////////////////////////////////////////////////////
	// ------------------------------------------------- Constructors
	/////////////////////////////////////////////////////////////////

	/**
	 * Empty constructor.
	 */
	
	public BojarczukEvaluator() 
	{
		super();
	}

	/////////////////////////////////////////////////////////////////
	// ------------------------------- Getting and setting properties
	/////////////////////////////////////////////////////////////////
	
	/**
	 * Get the dataset 
	 * 
	 * @return dataset
	 */
	
	public IDataset getDataset()
	{
		return dataset;
	}
	
	/**
	 * Set the dataset
	 * 
	 * @param dataset the dataset
	 */
	
	public void setDataset(IDataset dataset)
	{
		this.dataset = dataset;
	}
	
	/**
	 * Get the maximum derivation size
	 * 
	 * @return maxDerivSize
	 */
	public int getMaxDerivSize()
	{
		return maxDerivSize;
	}
	
	/**
	 * Set the maximum derivation size
	 * 
	 * @param maxDerivSize maximum derivation size
	 */
	public void setMaxDerivSize(int maxDerivSize)
	{
		this.maxDerivSize = maxDerivSize;
	}
	
	/////////////////////////////////////////////////////////////////
	// ------------------------ Overwriting AbstractEvaluator methods
	/////////////////////////////////////////////////////////////////
	
	/**
	 * Evaluates the individual and compute it fitness 
	 * 
	 * @param individual Individual to evaluate
	 */

	protected void evaluate(IIndividual individual) 
	{
		Rule rule = (Rule) ((SyntaxTreeRuleIndividual) individual).getPhenotype();
		
		int[] tp, fp, tn, fn;
		
		IMetadata metadata = getDataset().getMetadata();
		CategoricalAttribute catAttribute = (CategoricalAttribute) metadata.getAttribute(metadata.getClassIndex()); 
		int numClasses = catAttribute.getCategories().size();
		
		tp = new int [numClasses];
		tn = new int [numClasses];
		fn = new int [numClasses];
		fp = new int [numClasses];
		
		//Calculate the confusion matrix for each class
		for(IInstance instance : dataset.getInstances())
		{
			if((Boolean) rule.covers(instance))
			{		
				double value = instance.getValue(metadata.getClassIndex());
				tp[(int) value]++;
				for(int i=0; i<numClasses; i++)
					if(((int) value) != i)
						fp[i]++;
			}
			else
			{	
				double value = instance.getValue(metadata.getClassIndex());
					
				fn[(int) value]++;
				for(int i=0; i<numClasses; i++)
					if(((int) value) != i)
						tn[i]++;
			}
		}
					
		//Calculate the fitness for each class
		double se = -1, sp = 1, sy;
		double seAux, spAux;
		int bestClass = -1;
				
		for(int i=0; i<numClasses; i++)
		{
			if(tp[i]+fn[i] == 0)
				seAux = 1;
			else
				seAux = (double) tp[i]/(tp[i]+fn[i]);
			
			if(tn[i]+fp[i] == 0)
				spAux = 1;
			else
				spAux = (double) tn[i]/(tn[i]+fp[i]);
			
			if(seAux*spAux == se*sp)
				bestClass = i;
			
			if(seAux*spAux > se*sp)
			{
				se = seAux;
				sp = spAux;
				bestClass = i;
			}
		}
		
		// Assign as consequent the class that reports the best fitness
		rule.setConsequent(bestClass);
		
		double numnodes = rule.getAntecedent().size();	
		
		sy = (getMaxDerivSize() - 0.5*numnodes -0.5)/(getMaxDerivSize()-1);
		
		individual.setFitness(new SimpleValueFitness(se*sp*sy));
	}
	
	/**
	 * {@inheritDoc}
	 */
	
	public Comparator<IFitness> getComparator() 
	{		
		return comparator;
	}
}